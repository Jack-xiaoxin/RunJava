* [从进程到线程](#%E4%BB%8E%E8%BF%9B%E7%A8%8B%E5%88%B0%E7%BA%BF%E7%A8%8B)
* [线程的状态](#%E7%BA%BF%E7%A8%8B%E7%9A%84%E7%8A%B6%E6%80%81)
* [线程调度](#%E7%BA%BF%E7%A8%8B%E8%B0%83%E5%BA%A6)
  * [sleep与wait区别](#sleep%E4%B8%8Ewait%E5%8C%BA%E5%88%AB)
  * [yield/join](#yieldjoin)
  * [守护线程与非守护线程](#%E5%AE%88%E6%8A%A4%E7%BA%BF%E7%A8%8B%E4%B8%8E%E9%9D%9E%E5%AE%88%E6%8A%A4%E7%BA%BF%E7%A8%8B)
  * [中断线程](#%E4%B8%AD%E6%96%AD%E7%BA%BF%E7%A8%8B)
  * [从线程中抛出异常](#%E4%BB%8E%E7%BA%BF%E7%A8%8B%E4%B8%AD%E6%8A%9B%E5%87%BA%E5%BC%82%E5%B8%B8)
* [线程的活跃性问题](#%E7%BA%BF%E7%A8%8B%E7%9A%84%E6%B4%BB%E8%B7%83%E6%80%A7%E9%97%AE%E9%A2%98)
  * [多线程中的死锁](#%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%AD%E7%9A%84%E6%AD%BB%E9%94%81)
  * [多线程中的活锁](#%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%AD%E7%9A%84%E6%B4%BB%E9%94%81)
  * [多线程中的饥饿](#%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%AD%E7%9A%84%E9%A5%A5%E9%A5%BF)
* [线程安全](#%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8)
  * [三个基本概念](#%E4%B8%89%E4%B8%AA%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5)
  * [Java对线程安全的保证](#java%E5%AF%B9%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E7%9A%84%E4%BF%9D%E8%AF%81)
  * [线程同步的方法](#%E7%BA%BF%E7%A8%8B%E5%90%8C%E6%AD%A5%E7%9A%84%E6%96%B9%E6%B3%95)
* [线程间通信](#%E7%BA%BF%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1)
* [创建线程的数量](#%E5%88%9B%E5%BB%BA%E7%BA%BF%E7%A8%8B%E7%9A%84%E6%95%B0%E9%87%8F)
* [多线程中的设计模式](#%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%AD%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F)


在并发编程领域，有两大核心问题：一个是互斥，即同一时刻只允许一个线程访问共享资源；另一个是同步，即线程之间如何通信、协作。

从进程到线程
----------------

**进程**：每个进程都有独立的代码和数据空间（进程上下文），进程间的切换会有较大的开销，一个进程包含1--n个线程。**（进程是资源分配的最小单位）**

**线程**：同一类线程共享代码和数据空间，每个线程有独立的运行栈和程序计数器(PC)，线程切换开销小。**（线程是cpu调度的最小单位）**

在Java中有4种方式可以用来创建线程：

>   1.继承Thread类，重写run方法

>   2.实现Runnable接口，重写run方法

>   3.应用程序可以使用Executor框架来创建线程池

>   4.实现Callable接口

实现Runnable接口比继承Thread类所具有的优势：

>   1.适合多个相同的程序代码的线程去处理同一个资源

>   2.可以避免java中的单继承的限制

>   3.增加程序的健壮性，代码可以被多个线程共享，代码和数据独立

>   4.线程池只能放入实现Runable或callable类线程，不能直接放入继承Thread的类

>   5.runnable实现线程可以对线程进行复用，因为runnable是轻量级的对象，重复new不会耗费太大资源，而Thread则不然，它是重量级对象，而且线程执行完就完了，无法再次利用。

线程的状态
--------------

**新建状态（New）**：新创建了一个线程对象。

**就绪状态（Runnable）**：线程对象创建后，其他线程调用了该对象的start()方法。该状态的线程位于可运行线程池中，变得可运行，等待获取CPU的使用权。

**运行状态（Running）**：就绪状态的线程获取了CPU，执行程序代码。

**阻塞状态（Blocked）**：阻塞状态是线程因为某种原因放弃CPU使用权，暂时停止运行。直到线程进入就绪状态，才有机会转到运行状态。阻塞的情况分三种：

1.**等待阻塞**：运行的线程执行wait()方法，JVM会把该线程放入等待池中。(wait会释放持有的锁)

2.**同步阻塞**：运行的线程在获取对象的同步锁时，若该同步锁被别的线程占用，则JVM会把该线程放入锁池中。

**3.其他阻塞**：运行的线程执行sleep()或join()方法，或者发出了I/O请求时，JVM会把该线程置为阻塞状态。当sleep()状态超时、join()等待线程终止或者超时、或者I/O处理完毕时，线程重新转入就绪状态。（注意,sleep是不会释放持有的锁）。

**死亡状态（Dead）**：线程执行完了或者因异常退出了run()方法，该线程结束生命周期。

![https://img-blog.csdn.net/20150309140927553](media/4aedb9d9d47f02ec77420699a86f22a7.jpg)

[为什么 Java 线程没有 Running 状态](https://mp.weixin.qq.com/s/tNdUEkLGz9xrSEsRy-Ng-Q)

 线程调度
------------

###  sleep与wait区别

**sleep方**法属于Thread类中的静态方法，表示让一个线程进入睡眠状态，等待一定的时间之后，自动醒来进入到可运行状态，但是不会马上进入运行状态，因为线程调度机制恢复线程的运行也需要时间，一个线程对象调用了sleep方法之后，并不会释放他所持有的所有对象锁，所以也就不会影响其他进程对象的运行。**但在sleep的过程中过程中有可能被其他对象调用它的interrupt(),产生InterruptedException异常**，所以**sleep必须捕获异常。**

**注意**sleep是静态方法，也就是说它只对当前对象有效。通过 对象名.sleep()
想让该对象线程进入休眠是无效的，它只会让当前线程进入休眠。

**wait方法**是Object类里的方法，当一个线程执行到wait()方法时，它就进入到一个和该对象相关的等待池中，同时释放了锁对象，等待期间可以调用里面的同步方法，其他线程可以访问，等待时不拥有CPU的执行权，否则其他线程无法获取执行权。当一个线程执行了wait方法后，必须调用notify或者notifyAll方法才能唤醒，而且是随机唤醒，若是被其他线程抢到了CPU执行权，该线程会继续进入等待状态。由于锁对象可以时任意对象，所以wait方法必须定义在Object类中，因为Obeject类是所有类的基类。

**区别比较：**

1．这两个方法来自不同的类分别是Thread和Object。

2．最主要的区别是sleep方法没有释放锁，而wait方法释放了锁，使得其他线程可以使用同步控制块或者方法。

3．wait，notify和notifyAll只能在**同步控制方法或者同步控制块里**面使用，而sleep可以在任何地方使用(使用范围)。

4．**wait()和sleep()都可以通过interrupt()方法 打断线程的暂停状态
，从而使线程立刻抛出InterruptedException。**

**为什么wait、notify和notifyAll方法要和synchronized关键字一起使用？**

因为wait和notify、notifyAll方法是由确定的对象即锁对象来调用的，这一过程是线程通信。wait方法是使一个线程进入等待状态，并且释放其所持有的锁对象，notify方法是通知等待该锁对象的线程重新获得锁对象，然而如果没有获得锁对象，wait方法和notify方法都是没有意义的，因此必须先获得锁对象再对锁对象进行进一步操作于是才要把wait方法和notify方法写到同步方法和同步代码块中了。

sleep方法是让某个线程暂停运行一段时间，其控制范围是由当前线程决定，运行的主动权是由当前线程来控制（拥有CPU的执行权）。本质上是对线程的运行状态控制。

###  yield/join

yield方法是停止当前线程，让出CPU占有权，让同等优先权的线程或更高优先级的线程有执行的机会。yield()只是使当前线程重新回到可执行状态，所以执行yield()的线程有可能在进入到可执行状态后马上又被执行。

join方法是用于在某一个线程的执行过程中调用另一个线程执行，等到被调用的线程执行结束后，再继续执行当前线程。如：在main方法中调用t.join()，此时只有当t线程运行结束，main方法才会继续执行。

### 守护线程与非守护线程

所谓守护线程是指在程序运行的时候在后台提供一种通用服务的线程，比如垃圾回收线程，并且这种线程并不属于程序中不可或缺的部分。因此，当所有的非守护线程结束时，程序也就终止了，同时会杀死进程中的所有守护线程。反过来说，只要任何非守护线程还在运行，程序就不会终止。

**在使用守护线程时需要注意一下几点：**

1.thread.setDaemon(true)必须在thread.start()之前设置，否则会跑出一个IllegalThreadStateException异常，即不能把正在运行的常规线程设置为守护线程。

2.在Daemon线程中产生的新线程也是Daemon的。

3.守护线程应该永远不去访问固有资源，如文件、数据库，因为它会在任何时候甚至在一个操作的中间发生中断。

### 中断线程

中断线程有很多方法：

>   1.使用退出标志，使线程正常退出，也就是当run方法完成后线程终止。

>   2.通过return退出run方法

>   3.通过对有些状态中断抛异常退出。

Thread.interrupt()并不能使得线程被中断，线程还是会执行。最靠谱的方法就是设置一个全局的标记位，然后再Thread中去检查这个标记位，发现标记位改变则中断线程。

![](media/7b02d3d12c1f34841dc96a2c0a25f592.png)

### 从线程中抛出异常

首先明确线程代码的边界。其实很简单，Runnable接口的run方法所界定的边界就可以看作是线程代码的边界。Runnable接口中run方法原型如下：

**public void run();**

而所有的具体线程都实现这个方法，所以这里就明确了一点，**线程代码不能抛出任何checked异常**。所有的线程中的checked异常都只能被线程本身消化掉。

但是，线程代码中是可以抛出错误(Error)和运行级别异常(RuntimeException)的。Error通常Error应该留给JVM处理，而RuntimeException确是比较正常的，如果在运行过程中满足了某种条件导致线程必须中断，可以选择使用抛出运行级别异常来处理，当线程代码抛出运行级别异常之后，线程会中断。但是对开启子线程的主线程来说，并不受影响。正常情况下，如果不做特殊的处理，在主线程中是不能够捕获到子线程中的异常的。

**但是，给某个thread设置一个UncaughtExceptionHandler，**可以确保在该线程出现异常时能通过**回调UncaughtExceptionHandler接口的uncaughtException(…)
方法**来处理异常，这样的好处或者说目的是可以在线程代码边界之外（Thread的run()方法之外），有一个地方能处理未捕获异常。但是要特别明确的是：**虽然是在回调方法中处理异常，但**

**这个回调方法在执行时依然还在抛出异常的这个线程中**！另外还要特别说明一点：如果线程是通过线程池创建，线程异常发生时UncaughtExceptionHandler接口不一定会立即回调。

线程的活跃性问题
--------------------

### 多线程中的死锁

**所谓死锁是指多个线程因竞争资源而造成的一种僵局（互相等待，两个线程都处于阻塞状态，在等待获取锁），若无外力作用，这些进程都将无法向前推进。**

避**免死锁的三种方式：**

> 1. **加锁顺序**：所有的线程按照一定的顺序加锁。

> 2. **加锁时限**：在尝试获取锁的时候加一个超时时间，这也就意味着在尝试获取锁的过程中若超过了这个时限该线程则放弃对该锁请求。若一个线程没有在给定的时限内成功获得所有需要的锁，则会进行回退并释放所有已经获得的锁，然后**等待一段随机的时间再重试。**这段随机的等待时间让其它线程有机会尝试获取相同的这些锁，并且让该应用在没有获得锁的时候可以继续运行。

> 3.**死锁检测：**死锁检测是一个更好的死锁预防机制，它主要是针对那些不可能实现按序加锁并且锁超时也不可行的场景。每当一个线程获得了锁，会在线程和锁相关的数据结构中将其记下。除此之外，每当有线程请求锁，也需要记录在这个数据结构中。当一个线程请求锁失败时，这个线程可以遍历**锁的关系图看看是否有死锁发生**。那么当检测出死锁时，**一个可行的做法是释放所有锁，回退，并且等待一段随机的时间后重试**。这个和简单的加锁超时类似，不一样的是只有死锁已经发生了才回退，而不会是因为加锁的请求超时了。虽然有回退和等待，但是如果有大量的线程竞争同一批锁，它们还是会重复地死锁。 **一个更好的方案是给这些线程设置优先级**，让一个（或几个）线程回退，剩下的线程就像没发生死锁一样继续保持着它们需要的锁。如果赋予这些线程的优先级是固定不变的，同一批线程总是会拥有更高的优先级。为避免这个问题，可以在死锁发生的时候设置随机的优先级。

### 多线程中的活锁

**活锁是指线程一直处于运行状态，但却是在做无用功，而这个线程本身要完成的任务却一直无法进展**。生活中的典型例子：
两个人在窄路相遇，同时向一个方向避让，然后又向另一个方向避让，如此反复。

**解决协同活锁的一种方案是调整重试机制**。

比如引入一些随机性。例如如果检测到冲突，那么就暂停随机的一定时间进行重试。这回大大减少碰撞的可能性。典型的例子是以太网的CSMA/CD检测机制。另外为了避免可能的死锁，适当加入一定的重试次数也是有效的解决办法。尽管这在业务上会引起一些复杂的逻辑处理。

### 多线程中的饥饿

当线程长时间得不到所需资源，使线程难以推进时，**就发生饥饿**。若是长时间的处于饥饿状态导致后续已没有完成该线程任务的必要时，就称这个进程饿死了。饿死的线程是等待可以被释放，但不会分配给自己的资源。

比如如果线程T1占用了资源R，线程T2又请求封锁R，于是T2等待。T3也请求资源R，当T1释放了R上的封锁后，系统首先批准了T3的请求，T2仍然等待。然后T4又请求封锁R，当T3释放了R上的封锁之后，系统又批准了T4的请求......，T2可能永远等待。

**一般情况下，想要解决饥饿问题，就会需要对线程竞争资源的竞争力（优先级）进行评估，竞争力强（优先级高）的线程优先分配资源，然后才是竞争力弱的。**

线程安全
------------

当多个线程访问某个类时，不管运行时环境采用何种调度方式或者这些线程将如何交替执行，并且在主调代码中不需要任何额外的同步或协同，这个类都能表现出正确的行为，那么这个类就是线程安全的。

###  三个基本概念

在并发编程中，通常会遇到以下三个问题：原子性问题，可见性问题，有序性问题。

**原子性**：一个操作或者多个操作
要么全部执行并且执行的过程不会被任何因素打断，要么就都不执行。

**可见性**：当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值。

**有序性**：程序执行的顺序按照代码的先后顺序（逻辑顺序，可能会出现指令优化重排）执行。

要想并发程序正确地执行，必须要保证原子性、可见性以及有序性。只要有一个没有被保证，就有可能会导致程序运行不正确。

### Java内存模型

Java内存模型（Java Memory
Model，JMM）的主要目标是定义程序中各个变量的访问规则，**即在虚拟机中将变量存储到内存和从内存中取出变量这样底层细节，同时**屏蔽各个硬件平台和操作系统的内存访问差异，以实现让Java程序在各种平台下都能达到一致的内存访问效果。此处的变量与Java编程时所说的变量不一样，指包括了实例字段、静态字段和构成数组对象的元素，但是不包括局部变量与方法参数，后者是线程私有的，不会被共享。

Java内存模型中规定了所有的变量都存储在主内存中，每条线程还有自己的工作内存，线程的工作内存中保存了该线程使用到的变量到主内存副本拷贝，线程对变量的所有操作（读取、赋值）都必须在工作内存中进行，而不能直接读写主内存中的变量。不同线程之间无法直接访问对方工作内存中的变量，线程间变量值的传递均需要在主内存来完成，线程、主内存和工作内存的交互关系如下图所示：

![https://images0.cnblogs.com/i/475287/201403/091134177063947.jpg](media/b7f94146622574758fbe49f9785549ce.jpg)

为了获得较好的执行性能，Java内存模型并没有限制执行引擎使用处理器的寄存器或者高速缓存来提升指令执行速度，也没有限制编译器对指令进行重排序。也就是说，在java内存模型中，也会存在缓存一致性问题和指令重排序的问题。

在执行程序时为了提高性能，编译器和处理器经常会对指令进行重排序。实际上，正是由于编译器和处理器的一些优化，才是导致出现线程安全的根源。

虽然CPU、内存、I/O 设备都在不断迭代，不断朝着更快的方向努力。但是，在这个快速发展的过程中，有一个核心矛盾一直存在，就是这**三者的速度差异**。程序里大部分语句都要访问内存，有些还要访问 I/O，根据木桶理论（一只水桶能装多少水取决于它最短的那块木板），程序整体的性能取决于最慢的操作——读写 I/O 设备，也
就是说单方面提高 CPU 性能是无效的。为了合理利用 CPU 的高性能，平衡这三者的速度差异，计算机体系机构、操作系统、编译程序都做出了贡献，主要体现为：
* CPU 增加了缓存，以均衡与内存的速度差异
* 操作系统增加了进程、线程，以分时复用 CPU，进而均衡 CPU 与 I/O 设备的速度差异
* 编译程序优化指令执行次序，使得缓存能够得到更加合理地利用

但是并发程序很多诡异问题的根源也在这里：缓存导致了可见性问题，线程切换导致了原子性问题，编译优化导致了有序性问题


### Java对线程安全的保证

**原子性**

在Java中，对基本数据类型（除了long和double）的变量的**读取**和**赋值**操作是原子性操作，即这些操作是不可被中断的，要么执行，要么不执行。也就是说，只有简单的读取、赋值（而且必须是将数字赋值给某个变量，变量之间的相互赋值不是原子操作）才是原子操作。

如果要实现更大范围操作的原子性，可以通过synchronized和Lock来实现。由于synchronized和Lock能够保证任一时刻只有一个线程执行该代码块，那么自然就不存在原子性问题了，从而保证了原子性。

**可见性**

对于可见性，Java提供了volatile关键字来保证可见性。当一个共享变量被volatile修饰时，它会保证修改的值会立即被更新到主存，当有其他线程需要读取时，它会去内存中读取新值。相当于在禁用了缓存以及编译优化。

而普通的共享变量不能保证可见性，因为普通共享变量被修改之后，什么时候被写入主存是不确定的，当其他线程去读取时，此时内存中可能还是原来的旧值，因此无法保证可见性。

另外，通过synchronized和Lock也能够保证可见性，synchronized和Lock能保证同一时刻只有一个线程获取锁然后执行同步代码，并且在释放锁之前会将对变量的修改刷新到主存当中。因此可以保证可见性。

**有序性**

在Java内存模型中，允许编译器和处理器对指令进行重排序，但是重排序过程不会影响到单线程程序的执行，却会影响到多线程并发执行的正确性。在Java里面，可以通过volatile关键字来保证一定的“有序性”。另外可以通过synchronized和Lock来保证有序性，同样，synchronized和Lock保证每个时刻是有一个线程执行同步代码，相当于是让线程顺序执行同步代码，自然就保证了有序性。

另外，Java内存模型具备一些先天的“有序性”，即不需要通过任何手段就能够得到保证的有序性，这个通常也称为
**happens-before原则**:如果两个操作的执行次序无法从happens-before原则推导出来，那么它们就不能保证它们的有序性，虚拟机可以随意地对它们进行重排序。

下面就来具体介绍下happens-before原则（先行发生原则）：

**程序次序规则**：一个线程内，按照代码顺序，书写在前面的操作先行发生于书写在后面的操作。注意，虽然这条规则中提到“书写在前面的操作先行发生于书写在后面的操作”，这个应该是程序看起来执行的顺序是按照代码顺序执行的，**但是虚拟机可能会对程序代码进行指令重排序。虽然进行重排序，但是最终执行的结果是与程序顺序执行的结果一致的，它只会对不存在数据依赖性的指令进行重排序**。但是这个规则无法保证程序在多线程中执行的正确性。

**锁定规则**：一个unLock操作先行发生于后面对同一个锁额lock操作。也就是说无论在单线程中还是多线程中，同一个锁如果出于被锁定的状态，那么必须先对锁进行了释放操作，后面才能继续进行lock操作。

**volatile变量规则**：对一个变量的写操作先行发生于后面对这个变量的读操作。直观地解释就是，如果一个线程先去写一个变量，然后一个线程去进行读取，那么写入操作肯定会先行发生于读操作。

**传递规则**：如果操作A先行发生于操作B，而操作B又先行发生于操作C，则可以得出操作A先行发生于操作C。这个规则实际上就是体现happens-before原则具备传递性。

**线程启动规则**：Thread对象的start()方法先行发生于此线程的每个一个动作。

**线程中断规则**：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生。

**线程终结规则**：线程中所有的操作都先行发生于线程的终止检测，我们可以通过Thread.join()方法结束、Thread.isAlive()的返回值手段检测到线程已经终止执行。

**对象终结规则**：一个对象的初始化完成先行发生于它的finalize()方法的开始。

### 线程同步的方法

在多线程中线程的执行顺序是依靠哪个线程先获得到CUP的执行权谁就先执行，虽然说可以通过线程的优先权进行设置，但也只是获取CUP执行权的概率高点，也不一定必须先执行。

**同步方法**

即有synchronized关键字修饰的方法。由于Java的每个对象都有一个内置锁，当用此关键字修饰方法时，内置锁会保护整个方法。在调用该方法前，需要获得内置锁，否则就处于阻塞状态。

注：synchronized关键字也可以修饰静态方法，此时如果调用该静态方法，将会锁住整个类。这个方法可以是静态方法和非静态方法，但是不能是抽象类的抽象方法，也不能是接口中的接口方法。

线程在执行同步方法时是具有排它性的。当任意一个线程进入到一个对象的任意一个同步方法时，这个对象的所有同步方法都被锁定了，在此期间，其他任何线程都不能访问这个对象的任意一个同步方法，直到这个线程执行完它所调用的同步方法并从中退出，从而导致它释放了该对象的同步锁之后。在一个对象被某个线程锁定之后，其他线程是可以访问这个

对象的所有非同步方法的。

**同步代码块**

即有synchronized关键字修饰的语句块。被该关键字修饰的语句块会自动被加上内置锁，从而实现同步。

同步块是通过锁定一个指定的对象，来对同步块中包含的代码进行同步；而同步方法是对这个方法块里的代码进行同步，而这种情况下锁定的对象就是同步方法所属的主体对象自身。如果这个方法是静态同步方法呢？那么线程锁定的就不是这个类的对象了，也不是这个类自身，而是这个类对应的java.lang.Class类型的对象。同步方法和同步块之间的相互制约只限于同一个对象之间，所以静态同步方法只受它所属类的其它静态同步方法的制约，而跟这个类的实例（对象）没有关系。

如果一个对象既有同步方法，又有同步块，那么当其中任意一个同步方法或者同步块被某个线程执行时，这个对象就被锁定了，其他线程无法在此时访问这个对象的同步方法，也不能执行同步块。

synchronized的目的是使同一个对象的多个线程，在某个时刻只有其中的一个线程可以访问这个对象的synchronized
数据。每个对象都有一个“锁标志”，当这个对象的一个线程访问这个对象的某个synchronized
数据时，这个对象的所有被synchronized
修饰的数据将被上锁（因为“锁标志”被当前线程拿走了），只有当前线程访问完它要访问的synchronized
数据时，当前线程才会释放“锁标志”，这样同一个对象的其它线程才有机会访问synchronized
数据。

**wait与notify**

wait方法使一个线程处于等待状态，并且释放所持有的对象的lock。

sleep方法使一个正在运行的线程处于睡眠状态，是一个静态方法，调用此方法要捕捉InterruptedException异常。

notify():唤醒一个处于等待状态的线程，注意的是在调用此方法的时候，并不能确切的唤醒某一个等待状态的线程，而是由JVM确定唤醒哪个线程，而且不是按优先级。

allnotity():唤醒所有处入等待状态的线程，注意并不是给所有唤醒线程一个对象的锁，而是让它们竞争。

类似的还有**Condition的awiat和signal。**

**使用特殊域变量(volatile)实现线程同步**

volatile关键字为域变量的访问提供了一种免锁机制，使用volatile修饰域相当于告诉虚拟机该域可能会被其他线程更新，因此每次使用该域就要重新计算，而不是使用寄存器中的值。volatile不会提供任何原子操作，它也不能用来修饰final类型的变量

注：多线程中的非同步问题主要出现在对域的读写上，如果让域自身避免这个问题，则就不需要修改操作该域的方法。用final域，有锁保护的域和volatile域可以避免非同步的问题。

**使用重入锁实现线程同步**

在JavaSE5.0中新增了一个java.util.concurrent包来支持同步。

ReentrantLock类是可重入、互斥、实现了Lock接口的锁，它与使用synchronized方法和快具有相同的基本行为和语义，并且扩展了其能力。

**使用局部变量实现线程同步**

当使用ThreadLocal维护变量时，ThreadLocal为每个使用该变量的线程提供独立的变量副本，所以每一个线程都可以独立地改变自己的副本，而不会影响其它线程所对应的副本。

注：ThreadLocal与同步机制

>   a.ThreadLocal与同步机制都是为了解决多线程中相同变量的访问冲突问题。

>   b.前者采用以"空间换时间"的方法，后者采用以"时间换空间"的方式

**使用阻塞队列实现线程同步**

**ArrayBlockingQueue**：基于数组实现的一个阻塞队列，在创建ArrayBlockingQueue对象时必须制定容量大小。并且可以指定公平性与非公平性，默认情况下为非公平的，即不保证等待时间最长的队列最优先能够访问队列。

**LinkedBlockingQueue**：基于链表实现的一个阻塞队列，在创建LinkedBlockingQueue对象时如果不指定容量大小，则默认大小为Integer.MAX_VALUE。

**PriorityBlockingQueue**：以上2种队列都是先进先出队列，而PriorityBlockingQueue却不是，它会按照元素的优先级对元素进行排序，按照优先级顺序出队，每次出队的元素都是优先级最高的元素。注意，此阻塞队列为无界阻塞队列，即容量没有上限（通过源码就可以知道，它没有容器满的信号标志），前面2种都是有界队列。

**DelayQueue**：基于PriorityQueue，一种延时阻塞队列，DelayQueue中的元素只有当其指定的延迟时间到了，才能够从队列中获取到该元素。DelayQueue也是一个无界队列，因此往队列中插入数据的操作（生产者）永远不会被阻塞，而只有获取数据的操作（消费者）才会被阻塞。

使用上述介绍的队列可以实现一个类似于生产者-消费者模型。

**使用原子变量实现线程同步**

需要使用线程同步的根本原因在于对普通变量的操作不是原子的。

原子操作是指将**读取变量值、修改变量值、保存变量值看成一个整体来操作**，即这几种行为要么同时完成，要么都不完成。在java.util.concurrent.atomic包中提供了创建了原子类型变量的工具类，使用该类可以简化线程同步。比如AtomicInteger表可以用原子方式更新int的值，可用在应用程序中(如以原子方式增加的计数器)。

此外也可以通过通过同步辅助类CountDownLatch、CyclicBarrier和Semaphore等实现线程的同步。

线程间通信
----------

**等待通知机制**

等待通知模式是 Java 中比较经典的线程通信方式。两个线程通过对同一对象调用等待
wait() 和通知 notify() 方法来进行通讯。有一些需要注意:

wait()、notify()、notifyAll() 调用的前提都是获得了对象的锁(也可称为对象监视器)。

调用 wait() 方法后线程会释放锁，进入 WAITING
状态，该线程也会被移动到等待队列中。

调用notify()方法会将等待队列中的线程移动到同步队列中，线程状态也会更新为 BLOCKED

从wait()方法返回的前提是调用 notify() 方法的线程释放锁，wait()
方法的线程获得锁。

等待通知有着一个经典范式：

**线程 A 作为消费者：**

>   获取对象的锁。

>   进入while(判断条件)，并调用 wait() 方法。

>   当条件满足跳出循环执行具体处理逻辑。

**线程 B 作为生产者:**

>   获取对象锁。

>   更改与线程 A 共用的判断条件。

>   调用 notify() 方法。




**volatile 共享内存**

因为Java是采用共享内存的方式进行线程通信的，采用volatile修饰的变量可以保证线程间的可见性。

**CountDownLatch**

CountDownLatch 可以实现 join 相同的功能，但是更加的灵活。

**CyclicBarrier**

中文名叫做屏障或者是栅栏，也可以用于线程间通信。它可以等待 N
个线程都达到某个状态后继续运行的效果。

该工具可以实现 CountDownLatch 同样的功能，但是要更加灵活。甚至可以调用 reset()
方法重置 CyclicBarrier (需要自行捕获 BrokenBarrierException 处理) 然后重新执行。

**线程响应中断**

可以采用中断线程的方式来通信，调用了 thread.interrupt() 方法其实就是将 Thread
中的一个标志属性置为了true。并不是说调用了该方法就可以中断线程，如果不对这个标志进行响应其实是没有什么作用。

**对于正在运行的非阻塞线程来说,
只是改变了中断状态,不会对它的运行状态产生影响。**

对于可取消的阻塞状态（调用了 Thread.sleep(), Object.wait(),
Thread.join()方法）中的线程来说，这个线程收到中断信号后,
会抛出InterruptedException, 同时会把中断状态置回为false。

在Core
Java中有这样一句话：”没有任何语言方面的需求要求一个被中断的程序应该终止。中断一个线程只是为了引起该线程的注意，被中断线程可以决定如何应对中断
“。interrupt中断的是线程的某一部分业务逻辑，**前提是线程需要检查自己的中断状态(isInterrupted())**。但是当线程被阻塞的时候，调用它的interrput()方法。

### 创建线程的数量

使用多线程，本质上就是提升程序性能。
度量性能的指标有很多，但是有两个指标是最核心的，它们就是延迟和吞吐量。延迟指的是发出
请求到收到响应这个过程的时间；延迟越短，意味着程序执行得越快，性能也就越好。 吞吐量指
的是在单位时间内能处理请求的数量；吞吐量越大，意味着程序能处理的请求越多，性能也就越
好。这两个指标内部有一定的联系（同等条件下，延迟越短，吞吐量越大），但是由于它们隶属
不同的维度（一个是时间维度，一个是空间维度），并不能互相转换。

要想“降低延迟，提高吞吐量”，对应的方法呢，基本上有两个方向，一个方向是优化算法，另
一个方向是将硬件的性能发挥到极致。前者属于算法范畴，后者则是和并发编程息息相关了。那
计算机主要有哪些硬件呢？主要是两类：一个是 I/O，一个是 CPU。简言之，在并发编程领域，
提升性能本质上就是提升硬件的利用率，再具体点来说，就是提升 I/O 的利用率和 CPU 的利用
率。

创建多少线程合适，要看多线程具体的应用场景。程序一般都是 CPU 计算和 I/O 操作交
叉执行的，由于 I/O 设备的速度相对于 CPU 来说都很慢，所以大部分情况下，I/O 操作执行的
时间相对于 CPU 计算来说都非常长，这种场景一般都称为 I/O 密集型计算；和 I/O 密集型
计算相对的就是 CPU 密集型计算了，CPU 密集型计算大部分场景下都是纯 CPU 计算。I/O 密集
型程序和 CPU 密集型程序，计算最佳线程数的方法是不同的。

* 对于 CPU 密集型计算，多线程本质上是提升多核 CPU 的利用率，理论上“线程的数量 =CPU 核数”就是最合适的。不过在工
程上，线程的数量一般会设置为“CPU 核数 +1”，这样的话，当线程因为偶尔的内存页失效或
其他原因导致阻塞时，这个额外的线程可以顶上，从而保证 CPU 的利用率。
* 对于 I/O 密集型的计算场景，最佳的线程数是与程序中 CPU 计算和 I/O 操作的耗时比相关的，可以总结出这样一个公式：最佳线程数 =CPU 核数 * （1 +（I/O 耗时 / CPU 耗时））

>对于 I/O 密集型计算场景，I/O 耗时和 CPU 耗时的比值是一个关键参数，不幸的是这个参数是
未知的，而且是动态变化的，所以工程上需要估算这个参数，然后做各种不同场景下的压测来验证。

### 多线程中的设计模式
#### 不可变模式

多个线程同时读写同一共享变量存在并发问题，这里的必要条件之一是读写，如果只有读，而没有写，是没有并发问题的。

解决并发问题，其实最简单的办法就是让共享变量只有读操作，而没有写操作。这个办法如此重要，以至于被上升到了一种解决并发问题的设计模式：**不变性（Immutability）模式**。所谓不变性，简单来讲，就是对象一旦被创建之后，状态就不再发生变化。换句话说，就是变量一旦被赋值，就不允许修改了（没有写操
作）；没有修改操作，也就是保持了不变性。一个不可变的类具有三个属性：
* 类和属性都必须是 final 的
* 所有方法均是只读的
* 类的属性如果是引用型,该属性对应的类也需要满足不可变类的条件,且不能提供修改该属性的方法

>不可变对象虽然是线程安全的，但是并不意味着引用这些不可变对象的对象就是线程安全的。

具备不变性的对象，只有一种状态，这个状态由对象内部所有的不变属性共同决定。其实还有一种更简单的
不变性对象，那就是无状态。无状态对象内部没有属性，只有方法。除了无状态的对象，你可能还听说过无
状态的服务、无状态的协议等等。无状态有很多好处，最核心的一点就是性能。在多线程领域，无状态对象
没有线程安全问题，无需同步处理，自然性能很好；在分布式领域，无状态意味着可以无限地水平扩展，所
以分布式领域里面性能的瓶颈一定不是出在无状态的服务节点上。


#### Copy-on-Write模式

所谓Copy-on-Write，经常被缩写为COW或者CoW，顾名思义就是**写时复制**。

不可变对象的写操作往往都是使用Copy-on-Write方法解决的，当然Copy-on-Write的应用领域并不局限于Immutability模式。

Copy-on-Write是一项非常通用的技术方案，在很多领域都有着广泛的应用。不过，它也有缺点的，那就是
消耗内存，每次修改都需要复制一个新的对象出来，好在随着自动垃圾回收（GC）算法的成熟以及硬件的
发展，这种内存消耗已经渐渐可以接受了。

#### 线程本地存储模式
多个线程同时读写同一共享变量存在并发问题，但是没有共享变量也不会有并发问题。也就是说如果每个线程都拥有自己的变量，彼此之间不共享，也就没有并发问题了。
除了局部变量可以做到避免共享外，Java语言提供的线程本地存储（ThreadLocal）。Java的实现里面也有每个线程有一个内部有一个私有属性threadLocals，其类型就是ThreadLocalMap，ThreadLocalMap的Key是ThreadLocal。

![](media/1258jhvsavgkvbkgk433.png)

在Java的实现方案里面，ThreadLocal仅仅是一个代理工具类，内部并不持有任何与线程相关的数据，所有和线程相关的数据都存储在Thread里面，这样的设计容易理解。而从数据的亲缘性上来讲，ThreadLocalMap属于Thread也更加合理。当然还有一个更加深层次的原因，那就是不容易产生内存泄露。而Java的实现中Thread持有ThreadLocalMap，而且ThreadLocalMap里对ThreadLocal的引用还是弱引用（WeakReference），所以只要Thread对象可以被回收，那么ThreadLocalMap就能被回收。

Java的ThreadLocal实现应该称得上深思熟虑了，不过即便如此深思熟虑，还是不能百分百地让程序员避免内存泄露，例如在线程池中使用ThreadLocal，如果不谨慎就可能导致内存泄露。

在线程池中使用ThreadLocal为什么可能导致内存泄露呢？原因就出在线程池中线程的存活时间太长，往往
都是和程序同生共死的，这就意味着Thread持有的ThreadLocalMap一直都不会被回收，再加上
ThreadLocalMap中的Entry对ThreadLocal是弱引用（WeakReference），所以只要ThreadLocal结束了自己
的生命周期是可以被回收掉的。但是Entry中的Value却是被Entry强引用的，所以即便Value的生命周期结束
了，Value也是无法被回收的，从而导致内存泄露。那在线程池中，该如何正确使用ThreadLocal呢？其实很简单，既然JVM不能做到自动释放对Value的强引用，那使用try{}finally{}手动释放就可以了。

线程本地存储模式本质上是一种避免共享的方案，由于没有共享，所以自然也就没有并发问题。如果需要
在并发场景中使用一个线程不安全的工具类，最简单的方案就是避免共享。避免共享有两种方案，一种方案
是将这个工具类作为局部变量使用，另外一种方案就是线程本地存储模式。这两种方案，局部变量方案的缺
点是在高并发场景下会频繁创建对象，而线程本地存储方案，每个线程只需要创建一个工具类的实例，所以
不存在频繁创建对象的问题。


#### Guarded Suspension模式

多线程编程中，往往将一个任务分解为不同的部分，将其交由不同的线程来执行，这些线程相互协作的时候，会出现一个线程等待另一个线程一定操作过后才能进行的情景，这个时候就需要这个线程退出执行。

 Suspension是“挂起”、“暂停”的意思，而Guarded则是“保护”的意思，连在一起就是**保护性地暂停**：当线程在访问某个对象时，
发现条件不满足，就暂时挂起等待条件满足时再次访问。

下图就是Guarded Suspension模式的结构图，非常简单，一个对象GuardedObject，内部有一个成员变量
——受保护的对象，以及两个成员方法——get(Predicate<T> p)和onChanged(T obj)方法。GuardedObject的核心是：get()
方法通过条件变量的await()方法实现等待，onChanged()方法通过条件变量的signalAll()方法实现唤醒功能。
 
 ![](https://raw.githubusercontent.com/LLLRS/git_resource/master/12ghvsvhshjjvj.png)
 
下面的示例代码是扩展Guarded Suspension模式的实现，扩展
后的GuardedObject内部维护了一个Map，其Key是消息id，而Value是GuardedObject对象实例，同时
增加了静态方法create()和fireEvent()；create()方法用来创建一个GuardedObject对象实例，并根据key值将
其加入到Map中，而fireEvent()方法则是根据id唤醒对应的GuardedObject对象。


```
public class GuardedObject<T>{
    //受保护的对象
    T obj;
    final Lock lock = new ReentrantLock();
    final Condition done = lock.newCondition();
    final int timeout=1;
    
      //保存所有GuardedObject 主要用于区分不同的消息
    final static Map<Object, GuardedObject> gos=new ConcurrentHashMap<>();
    //静态⽅法创建GuardedObject
    static <K> GuardedObject create(K key){
        GuardedObject go=new GuardedObject();
        gos.put(key, go);
        return go;
    }

    static <K, T> void fireEvent(K key, T obj){
        GuardedObject go=gos.remove(key);
        if (go != null){
            go.onChanged(obj);
        }
    }
    
    //获取受保护对象
    T get(Predicate<T> p) {
        lock.lock();
        try {
            //MESA管程推荐写法
            while(!p.test(obj)){
                done.await(timeout, TimeUnit.SECONDS);
            }
        }catch(InterruptedException e){
            throw new RuntimeException(e);
        }finally{
            lock.unlock();
        }

        //返回⾮空的受保护对象
        return obj;
    }
    
    
    //事件通知⽅法
    void onChanged(T obj) {
        lock.lock();
        try {
            this.obj = obj;
            done.signalAll();
        } finally {
            lock.unlock();
        }
    }
}

```


Guarded Suspension模式本质上是一种等待唤醒机制的实现，只不过Guarded Suspension模式将其规范化
了。规范化的好处是你无需重头思考如何实现，也无需担心实现程序的可理解性问题。


#### Thread-Per-Message

Thread-Per-Message模式是一种最简单实用的分工方法，简言之就是为每个任务分配一个独立的线程。比如一个HTTP Server，很显然只能在主线程中接收请求，而不能处理HTTP请求，因为如果在主线程中处理HTTP请求的话，那同一时间只能处理一个请求，太慢了！可以利用代办的思路，创建一个子线程，委托子线程去处理HTTP请求。

Thread-Per-Message模式的一个最经典的应用场景是网络编程里服务端的实现，服务端为每个客户端请求
创建一个独立的线程，当线程处理完请求后，自动销毁，这是一种最简单的并发处理网络请求的方法。但是这种实现方案是不具备可行
性的，原因在于Java中的线程是一个重量级的对象，创建成本很高，一方面创建线程比较耗时，另一方面线
程占用的内存也比较大。所以，为每个请求创建一个新的线程并不适合高并发场景。但是Thread-Per-Message模式作为一种最简单的分工方案，Java语言支持不了，显然是Java语言本身的问题。

Java语言里，Java线程是和操作系统线程一一对应的，这种做法本质上是将Java线程的调度权完全委托给操
作系统，而操作系统在这方面非常成熟，所以这种做法的好处是稳定、可靠，但是也继承了操作系统线程的
缺点：创建成本高。为了解决这个缺点，Java并发包里提供了线程池等工具类。这个思路在很长一段时间里
都是很稳妥的方案，但是这个方案并不是唯一的方案。

业界还有另外一种方案，叫做轻量级线程。这个方案在Java领域知名度并不高，但是在其他编程语言里却叫
得很响，例如Go语言、Lua语言里的协程，本质上就是一种轻量级的线程。轻量级的线程，创建的成本很
低，基本上和创建一个普通对象的成本相似；并且创建的速度和内存占用相比操作系统线程至少有一个数量
级的提升，所以基于轻量级线程实现Thread-Per-Message模式就完全没有问题了。

#### WorkerThread模式

Worker Thread模式能避免线程频繁创建、销毁的问题，而且能够限制线程的最大数量。Java语言里可以直
接使用线程池来实现Worker Thread模式，线程池是一个非常基础和优秀的工具类，甚至有些大厂的编码规
范都不允许用new Thread()来创建线程的，必须使用线程池。

不过使用线程池还是需要格外谨慎的，除了要了解如何正确创建线程池、如何避免线程死锁问题，
还需要注意使用ThreadLocal内存泄露问题。同时对于提交到线程池的任务，还要做好异常
处理，避免异常的任务从眼前溜走，从业务的角度看，有时没有发现异常的任务后果往往都很严重。


此外，使用线程池过程中，还要注意一种线程死锁的场景。如果提交到相同线程池的任务不是相互独立的，而是有依赖关系的，那么就有可能导致线程死锁。具体现象是应用每运行一段时间偶尔就会处于无响应的状态，监控数据看上去一切都正常，但是实际上已经不能正常工作了。有一个可能的原因是由于线程池中线程数目过少，导致相互依赖的线程不能执行，这种情况下最简单粗暴的办法就是将线程池的最大线程数调大，如果能够确定任务
的数量不是非常多的话，这个办法也是可行的，否则这个办法就行不通了。其实这种问题通用的解决方案是
为不同的任务创建不同的线程池。
















